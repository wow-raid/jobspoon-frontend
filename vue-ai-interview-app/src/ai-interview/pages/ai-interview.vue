<template>
  <v-container v-if="!start" align="center">
    <div :style="interviewContainerStyle">
      <v-icon>mdi-account-tie</v-icon><br />
      <div v-html="startMessage"></div>

      <div :style="mt16Style">
        <video
          ref="previewVideo"
          autoplay
          playsinline
          muted
          :style="previewVideoStyle"
        />
        <div :style="buttonGroupStyle">
          <v-btn color="info" @click="checkMediaReady">ì¹´ë©”ë¼/ë§ˆì´í¬ ìƒíƒœ í™•ì¸</v-btn>
          <v-btn color="success" @click="startRecording">ğŸ¥ ë…¹í™” ì‹œì‘</v-btn>
          <v-btn color="error" @click="stopRecording">ğŸ›‘ ë…¹í™” ì¢…ë£Œ</v-btn>
          <v-btn color="warning" @click="playRecording" :disabled="!recordedBlob">â–¶ ì˜ìƒ ì¬ìƒ</v-btn>
        </div>
      </div>
      <v-btn color="primary" :style="mt4Style" @click="handleStartInterview" :disabled="!mediaChecked">
        ë©´ì ‘ ì‹œì‘
      </v-btn>
    </div>
  </v-container>

  <v-container v-else fluid :style="pa0Style">
    <div :style="videoWrapStyle">
      <v-row :style="videoRowStyle" no-gutters>
        <v-col cols="6" :style="colRightStyle">
          <div :style="videoBoxStyle">
            <img :src="hhImage" alt="ë©´ì ‘ê´€" :style="interviewerImageStyle" />
          </div>
        </v-col>
        <v-col :style="colSpacerStyle"></v-col>
        <v-col cols="6" :style="colLeftStyle">
          <div :style="videoBoxStyle">
            <video
              ref="userVideo"
              v-show="start"
              autoplay
              playsinline
              muted
              :style="userVideoStyle"
            ></video>
          </div>
        </v-col>
      </v-row>
    </div>
    <v-col :style="colSpacerStyle"></v-col>
    <v-col cols="12" :style="centeredColStyle">
      <div
        v-if="visible"
        :style="[interviewContainerStyle, centeredTextBoxStyle, { marginTop: 0, width: '75%' }]"
      >
        <v-icon>mdi-account-tie</v-icon><br />
        <div v-html="startMessage"></div>
      </div>
      <div
        v-else
        :style="[interviewContainerStyle, centeredTextBoxStyle, { marginTop: 0, width: '75%' }]"
      >
        <v-icon>mdi-account-tie</v-icon><br />
        <h2 v-html="formattedAIMessage"></h2>
        <br />
        <div :style="[timerStyle, remainingTime <= 10 ? redTextStyle : {}]">
          ë‚¨ì€ ì‹œê°„: {{ Math.floor(remainingTime / 60) }}:{{ (remainingTime % 60).toString().padStart(2, "0") }}
        </div>
      </div>
    </v-col>

    <div v-if="isLoading && !finished" :style="aiMessageStyle">
      <br />
      <p><strong>ë‹¤ìŒ ì§ˆë¬¸ì„ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤.</strong></p>
      <v-icon>mdi-account-tie</v-icon>
      <div :style="loadingMessageStyle">
        <div :style="dotStyle"></div>
        <div :style="dotStyle"></div>
        <div :style="dotStyle"></div>
      </div>
    </div>

    <v-container v-if="start && !visible" :style="inputAreaStyle">
      <div :style="buttonGroupStyle">
        <button :style="sendButtonStyle" @click="startSTT" :disabled="recognizing">
          {{ recognizing ? "ë…¹ìŒ ì¤‘..." : "ë§í•˜ê¸°" }}
        </button>
        <button @click="replayQuestion" :style="plainButtonStyle">ğŸ—£ AI ì§ˆë¬¸ ë“£ê¸°</button>
      </div>
      <v-btn color="primary" @click="onAnswerComplete" :disabled="isGenerating">
        <template v-if="isGenerating && finished.value">
          ê²°ê³¼ ìƒì„± ì¤‘...
        </template>
        <template v-else-if="isGenerating"> ì§ˆë¬¸ ìƒì„± ì¤‘... </template>
        <template v-else> ë‹µë³€ ì™„ë£Œ </template>
      </v-btn>
      <div :style="sttLogStyle">
        <template v-if="recognizing">
          <p>ğŸ™ï¸ ì…ë ¥ ì¤‘ì…ë‹ˆë‹¤...</p>
        </template>
        <template v-else-if="isGenerating">
          <p style="color: gray">
            {{
              finished.value
                ? "ğŸ“ ê²°ê³¼ë¥¼ ìƒì„±í•˜ê³  ìˆì–´ìš”..."
                : "ğŸ¤– ë‹¤ìŒ ì§ˆë¬¸ì„ ìƒì„±í•˜ê³  ìˆì–´ìš”..."
            }}
          </p>
          <p v-if="sttLog !== ''"><strong>STT ê²°ê³¼:</strong> {{ sttLog }}</p>
        </template>
        <template v-else-if="sttLog !== ''">
          <p><strong>STT ê²°ê³¼:</strong> {{ sttLog }}</p>
        </template>
      </div>
      <v-text-field
        v-model="sttLog"
        label="ê°œë°œ ì¤‘: ë‹µë³€ ì§ì ‘ ì…ë ¥"
        hide-details
        dense
        solo
        style="max-width: 300px"
      />
    </v-container>
  </v-container>
</template>

<script setup>
import { ref, computed, onMounted, onBeforeUnmount, nextTick } from "vue";
import { useAiInterviewStore } from "../stores/aiInterviewStore";
import { useRouter, onBeforeRouteLeave } from "vue-router";
import "@mdi/font/css/materialdesignicons.css";
import hhImage from "@/assets/images/fixed/al3.png";
import { useHead } from '@vueuse/head'

useHead({
  title: "AI ëª¨ì˜ ë©´ì ‘ ì‹œì‘ | ì¡ìŠ¤í‹±(JobStick)",
  meta: [
    { name: "description", content: "AI ê¸°ë°˜ ëª¨ì˜ ë©´ì ‘ì„ ì§„í–‰í•˜ê³ , ì›í•˜ëŠ” ê¸°ì—…, ì§ë¬´ì— ëŒ€í•œ ê¸°ìˆ  ë©´ì ‘ì„ ëŒ€ë¹„í•´ë³´ì„¸ìš”." },
    { name: "keywords", content: "AI ë©´ì ‘, ëª¨ì˜ ë©´ì ‘, ê¸°ìˆ  ë©´ì ‘, AI ê¸°ë°˜ ëª¨ì˜ ë©´ì ‘, ì¹´ë©”ë¼ í…ŒìŠ¤íŠ¸, ë©´ì ‘ ì¤€ë¹„, ì˜¨ë¼ì¸ ë©´ì ‘, ë¹„ëŒ€ë©´ ë©´ì ‘, ì¸ê³µì§€ëŠ¥ ë©´ì ‘, JobStick, job-stick, ì¡ìŠ¤í‹±, ê°œë°œì í”Œë«í¼, ê°œë°œì ì·¨ì—…" },
    { property: "og:title", content: "AI ëª¨ì˜ ë©´ì ‘ ì¤€ë¹„ - ì¡ìŠ¤í‹±(JobStick)" },
    { property: "og:description", content: "ì¡ìŠ¤í‹±(JobStick)ì—ì„œ AI ê¸°ë°˜ì˜ ì‹¤ì „ ë©´ìŠµ ì—°ìŠµì„ í†µí•´ ê¸°ìˆ  ë©´ì ‘ì˜ ì‹¤ì „ ê°ê°ì„ ê¸¸ëŸ¬ë³´ì„¸ìš”." },
    { property: "og:image", content: "" },
    { name: "robots", content: "index, follow" },
  ],
});

// ==== ìŠ¤íƒ€ì¼ ìƒìˆ˜ (ìƒëµì—†ì´ ì „ì²´) ====
const interviewContainerStyle = {
  marginTop: "32px",
  border: "1px solid #333",
  padding: "16px",
  borderRadius: "10px",
  width: "70%",
  display: "flex",
  flexDirection: "column",
  alignItems: "center",
  textAlign: "center",
  background: "#fff"
};
const mt16Style = { marginTop: "16px" };
const mt4Style = { marginTop: "16px" };
const previewVideoStyle = {
  width: "250px",
  height: "188px",
  background: "#000",
  borderRadius: "8px"
};
const buttonGroupStyle = {
  display: "flex",
  flexWrap: "wrap",
  justifyContent: "center",
  gap: "12px",
  marginTop: "12px"
};
const sendButtonStyle = {
  padding: "10px 12px",
  backgroundColor: "black",
  color: "white",
  border: "none",
  borderRadius: "20px",
  cursor: "pointer",
  fontSize: "16px",
  height: "40px",
  display: "flex",
  alignItems: "center",
  justifyContent: "center",
  minWidth: "100px",
  boxSizing: "border-box"
};
const plainButtonStyle = {
  padding: "10px 12px",
  backgroundColor: "#f1f1f1",
  color: "#222",
  border: "none",
  borderRadius: "20px",
  cursor: "pointer",
  fontSize: "16px",
  height: "40px",
  minWidth: "100px",
  boxSizing: "border-box"
};
const videoWrapStyle = {
  width: "75%",
  margin: "0 auto",
  paddingTop: "16px"
};
const videoRowStyle = {
  marginTop: "24px",
  marginBottom: "24px"
};
const colRightStyle = {
  display: "flex",
  justifyContent: "flex-end",
  padding: 0
};
const colLeftStyle = {
  display: "flex",
  justifyContent: "flex-start",
  padding: 0
};
const colSpacerStyle = {
  maxWidth: "16px",
  padding: 0
};
const videoBoxStyle = {
  width: "100%",
  aspectRatio: "4 / 3",
  border: "2px solid #ccc",
  borderRadius: "12px",
  overflow: "hidden",
  display: "flex",
  justifyContent: "center",
  alignItems: "center",
  backgroundColor: "#000"
};
const interviewerImageStyle = {
  width: "100%",
  height: "100%",
  objectFit: "cover"
};
const userVideoStyle = {
  width: "100%",
  height: "100%",
  objectFit: "cover"
};
const centeredColStyle = {
  maxWidth: "100%",
  display: "flex",
  justifyContent: "center",
  padding: 0,
  marginTop: "16px"
};
const centeredTextBoxStyle = {
  display: "flex",
  flexDirection: "column",
  alignItems: "center",
  textAlign: "center"
};
const timerStyle = {
  fontWeight: "bold",
  margin: "16px 0",
  fontSize: "20px"
};
const redTextStyle = {
  color: "red"
};
const aiMessageStyle = {
  margin: "20px 0",
  textAlign: "center"
};
const loadingMessageStyle = {
  display: "flex",
  alignItems: "center",
  gap: "6px",
  justifyContent: "center"
};
const dotStyle = {
  width: "10px",
  height: "10px",
  borderRadius: "50%",
  backgroundColor: "#6366f1",
  margin: "0 2px",
  animation: "dot-blink 1.4s infinite both"
};
const inputAreaStyle = {
  display: "flex",
  alignItems: "center",
  justifyContent: "center",
  gap: "20px",
  width: "50%",
  marginBottom: 0
};
const sttLogStyle = {
  marginTop: "8px",
  textAlign: "center"
};
const pa0Style = { padding: 0 };

// ==== ë¯¸ë””ì–´ ì¿¼ë¦¬ ë° ì• ë‹ˆë©”ì´ì…˜ ì§ì ‘ ë™ì  ì‚½ì… ====
if (typeof window !== "undefined") {
  const styleTag = document.createElement("style");
  styleTag.textContent = `
    @media (max-width: 768px) {
      .button-group, [style*="display: flex"][style*="gap: 12px"] {
        flex-direction: column !important;
        align-items: stretch !important;
      }
      .button-group > *, [style*="display: flex"][style*="gap: 12px"] > * {
        width: 100% !important;
      }
      .input-area, [style*="width: 50%"] {
        width: 100% !important;
      }
    }
    @keyframes dot-blink {
      0%, 80%, 100% { opacity: 0; }
      40% { opacity: 1; }
    }
  `;
  document.head.appendChild(styleTag);
}

// ======= script ë¡œì§ (ì „ë¶€) =======
const router = useRouter();
const aiInterviewStore = useAiInterviewStore();

const start = ref(false);
const visible = ref(true);
const isLoading = ref(false);
const finished = ref(false);
const recognizing = ref(false);
const sttLog = ref("");
const currentAIMessage = ref("");
const currentQuestionId = ref(1);
const currentInterviewId = ref(null);
const remainingTime = ref(90);
const timer = ref(null);
const maxQuestionId = ref(10);
const startMessage = ref("");
const userVideo = ref(null);
const mediaChecked = ref(false);
const previewVideo = ref(null);
const mediaStream = ref(null);
const isGenerating = ref(false);

const mapCompanyName = (original) => {
  const mapping = {
    ë‹¹ê·¼ë§ˆì¼“: "danggeun",
    Toss: "toss",
    "SK-encore": "sk_encore",
    "KT M mobile": "kt_mobile",
  };
  return mapping[original] || original.toLowerCase().replace(/[\s-]+/g, "_");
};

const checkMediaReady = async () => {
  try {
    const stream = await navigator.mediaDevices.getUserMedia({
      video: true,
      audio: true,
    });
    mediaChecked.value = true;
    alert("ë§ˆì´í¬ì™€ ì¹´ë©”ë¼ê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.");
    mediaStream.value = stream;
    if (previewVideo.value) previewVideo.value.srcObject = stream;
  } catch (err) {
    alert("ë§ˆì´í¬ ë˜ëŠ” ì¹´ë©”ë¼ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ê¶Œí•œì„ í™•ì¸í•˜ì„¸ìš”.");
    mediaChecked.value = false;
  }
};

const recordedVideo = ref(null);
const recordedBlob = ref(null);
let recordingStream = null;
let recorder = null;
let chunks = [];
const startRecording = async () => {
  try {
    recordingStream = await navigator.mediaDevices.getUserMedia({
      video: true,
      audio: true,
    });
    if (previewVideo.value) previewVideo.value.srcObject = recordingStream;

    chunks = [];
    recorder = new MediaRecorder(recordingStream, { mimeType: "video/webm" });

    recorder.ondataavailable = (event) => {
      if (event.data.size > 0) {
        chunks.push(event.data);
      }
    };

    recorder.onstop = () => {
      recordedBlob.value = new Blob(chunks, { type: "video/webm" });
      const videoURL = URL.createObjectURL(recordedBlob.value);
      localStorage.setItem("interviewRecordingUrl", videoURL);
      if (previewVideo.value) {
        previewVideo.value.srcObject = null;
        previewVideo.value.src = videoURL;
        previewVideo.value.controls = true;
        previewVideo.value.play();
      }
    };
    recorder.start();
    alert("ë…¹í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤ë‹¤");
  } catch (err) {
    console.error("ğŸ¥ ë…¹í™” ì‹œì‘ ì‹¤íŒ¨:", err);
    alert("ë…¹í™” ì‹œì‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.");
  }
};
const stopRecording = () => {
  if (recorder && recorder.state === "recording") {
    recorder.stop();
    if (recordingStream) {
      recordingStream.getTracks().forEach((track) => track.stop());
    }
    alert("ë…¹í™” ì¢…ë£Œë¨");
  }
};

let recognition;
const synth = process.client ? window.speechSynthesis : null;
let currentUtteance = null;

onMounted(async () => {
  try {
    const videoOnlyStream = await navigator.mediaDevices.getUserMedia({
      video: true,
    });
    if (previewVideo.value) {
      previewVideo.value.srcObject = videoOnlyStream;
    }
  } catch (err) {
    console.error("previewVideo ì¹´ë©”ë¼ ì—°ê²° ì‹¤íŒ¨:", err);
  }
  if (process.client) {
    speakStartMessage();

    await nextTick();

    const SpeechRecognition =
      window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SpeechRecognition) {
      alert("ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.");
      return;
    }

    recognition = new SpeechRecognition();
    recognition.lang = "ko-KR";
    recognition.continuous = true;
    recognition.interimResults = true;
    recognition.onstart = () => (recognizing.value = true);
    recognition.onend = () => (recognizing.value = false);
    recognition.onerror = () => (recognizing.value = false);
    recognition.onresult = (event) => {
      let finalTranscript = "";
      for (let i = event.resultIndex; i < event.results.length; ++i) {
        if (event.results[i].isFinal) {
          finalTranscript += event.results[i][0].transcript;
        }
      }
      sttLog.value += finalTranscript;
    };

    window.addEventListener("beforeunload", handleBeforeUnload);
  }
});

const showWarning = ref(true);

const speakStartMessage = () => {
  startMessage.value = `
    <strong style="display: flex; flex-direction: column; align-items: center;">
      <span style="margin-bottom: 8px;">AI ëª¨ì˜ ë©´ì ‘ì´ ê³§ ì‹œì‘ë©ë‹ˆë‹¤.</span>
      <span style="margin-bottom: 8px;">ë©´ì ‘ ì§ˆë¬¸ì´ í™”ë©´ì— í‘œì‹œë˜ë©°, ìë™ìœ¼ë¡œ ìŒì„±ìœ¼ë¡œ ì½ì–´ë“œë¦½ë‹ˆë‹¤.</span>
      <span style="margin-bottom: 8px;"><mark style="background: #ffecb3;">ë§í•˜ê¸° ë²„íŠ¼</mark>ì„ ëˆŒëŸ¬ ë‹µë³€ì„ ì‹œì‘í•´ ì£¼ì„¸ìš”.</span>
      <span style="margin-bottom: 8px;">ë§ˆì´í¬ì™€ ì¹´ë©”ë¼ê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™ ì¤‘ì¸ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”.</span>
      ${
        showWarning.value
          ? '<span style="color: red; font-weight: bold;">â€» ì¹´ë©”ë¼/ë§ˆì´í¬ ìƒíƒœ í™•ì¸ì„ ì²´í¬í•´ì•¼ ë©´ì ‘ ì‹œì‘ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.</span>'
          : ""
      }
    </strong>
  `;
};

const formattedAIMessage = computed(() => {
  return currentAIMessage.value.replace(/([.?])/g, "$1<br>");
});

const replayQuestion = () => {
  if (synth?.speaking) synth.cancel();
  const utterance = new SpeechSynthesisUtterance(currentAIMessage.value);
  utterance.lang = "ko-KR";
  utterance.rate = 0.85;
  utterance.pitch = 1.0;
  setTimeout(() => synth?.speak(utterance), 100);
};

const handleBeforeUnload = (event) => {
  if (start.value && !finished.value) {
    event.preventDefault();
    event.returnValue = "ë©´ì ‘ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ë‚˜ê°€ì‹œê² ìŠµë‹ˆê¹Œ?";
  }
};

const speakCurrentMessage = () => {
  clearInterval(timer.value);
  remainingTime.value = 90;
  currentUtteance = new SpeechSynthesisUtterance(currentAIMessage.value);
  currentUtteance.lang = "ko-KR";
  currentUtteance.rate = 0.85;
  currentUtteance.pitch = 1.0;
  currentUtteance.onend = () => startTimer();
  synth?.speak(currentUtteance);
};

const showStartMessage = () => {
  visible.value = false;
  speakCurrentMessage();
};

const startTimer = () => {
  clearInterval(timer.value);
  timer.value = setInterval(() => {
    if (remainingTime.value > 0) {
      remainingTime.value--;
    } else {
      clearInterval(timer.value);
      onAnswerComplete();
    }
  }, 1000);
};

const startSTT = () => {
  if (recognition && !recognizing.value) {
    sttLog.value = "";
    recognition.start();
  }
};
const startRecordingAuto = async () => {
  try {
    recordingStream = await navigator.mediaDevices.getUserMedia({
      video: true,
      audio: true,
    });
    if (userVideo.value) {
      userVideo.value.srcObject = recordingStream;
    }
    chunks = [];
    recorder = new MediaRecorder(recordingStream, { mimeType: "video/webm" });
    recorder.ondataavailable = (event) => {
      if (event.data.size > 0) chunks.push(event.data);
    };
    recorder.onstop = () => {
      recordedBlob.value = new Blob(chunks, { type: "video/webm" });
      const videoURL = URL.createObjectURL(recordedBlob.value);
      localStorage.setItem("interviewRecordingUrl", videoURL);
    };
    recorder.start();
    console.log("ë…¹í™” ì‹œì‘");
  } catch (err) {
    console.error("ë…¹í™” ì‹¤íŒ¨");
  }
};
const stopRecordingAuto = () => {
  if (recorder && recorder.state === "recording") {
    recorder.stop();
    if (recordingStream) {
      recordingStream.getTracks().forEach((track) => track.stop());
    }
    console.log("ë…¹í™” ì¢…ë£Œ");
  }
};
const handleStartInterview = async () => {
  const info = JSON.parse(localStorage.getItem("interviewInfo") || "{}");
  const processedCompanyName = mapCompanyName(info.company);

  if (!info.tech || !info.exp) {
    alert("ë©´ì ‘ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°‘ë‹ˆë‹¤.");
    router.push("/ai-interview");
    return;
  }
  start.value = true;
  await startRecordingAuto();

  showWarning.value = false;
  speakStartMessage();

  const res = await aiInterviewStore.requestCreateInterviewToDjango({
    userToken: localStorage.getItem("userToken"),
    jobCategory: info.tech,
    experienceLevel: info.exp,
    academicBackground: info.academic,
    projectExperience: info.project,
    interviewTechStack: info.skills,
    companyName: processedCompanyName,
  });
  currentInterviewId.value = Number(res.interviewId);
  currentQuestionId.value = 1;
  currentAIMessage.value = res.question;
  const utterance = new SpeechSynthesisUtterance(
    "AI ëª¨ì˜ ë©´ì ‘ì´ ê³§ ì‹œì‘ë©ë‹ˆë‹¤. ë©´ì ‘ ì§ˆë¬¸ì´ í™”ë©´ì— í‘œì‹œë˜ë©°, ìë™ìœ¼ë¡œ ìŒì„±ìœ¼ë¡œ ì½ì–´ë“œë¦½ë‹ˆë‹¤."
  );
  utterance.lang = "ko-KR";
  utterance.rate = 1;
  utterance.pitch = 1;
  utterance.onend = () => showStartMessage();
  synth?.cancel();
  synth?.speak(utterance);
};

const onAnswerComplete = async () => {
  isGenerating.value = true;

  clearInterval(timer.value);
  if (recognition && recognizing.value) recognition.stop();

  if (!sttLog.value.trim()) {
    alert("ìŒì„± ì¸ì‹ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.");
    isGenerating.value = false;
    return;
  }
  if (currentQuestionId.value >= maxQuestionId.value) {
    alert("ëª¨ë“  ë©´ì ‘ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤");
    finished.value = true;
    isGenerating.value = true;
    return;
  }

  const info = JSON.parse(localStorage.getItem("interviewInfo") || "{}");
  const processedCompanyName = mapCompanyName(info.company);
  const payload = {
    userToken: localStorage.getItem("userToken"),
    interviewId: currentInterviewId.value,
    questionId: currentQuestionId.value,
    answerText: sttLog.value,
    jobCategory: info.tech,
    experienceLevel: info.exp,
    academicBackground: info.academic,
    projectExperience: info.project,
    interviewTechStack: info.skills,
    companyName: processedCompanyName,
  };
  await aiInterviewStore.requestCreateAnswerToDjango(payload);

  let nextQuestion = null;
  let nextQuestionId = null;
  if (currentQuestionId.value === 1) {
    const followUp = await aiInterviewStore.requestFollowUpQuestionToDjango(
      payload
    );
    nextQuestion = followUp?.questions?.[0];
    nextQuestionId = followUp?.questionIds?.[0];
  } else if (currentQuestionId.value === 2) {
    const projectMain =
      await aiInterviewStore.requestProjectCreateInterviewToDjango(payload);
    nextQuestion = projectMain?.question?.[0];
    nextQuestionId = projectMain?.questionId;
  } else if (currentQuestionId.value === 3 || currentQuestionId.value === 4) {
    const projectFollowUp =
      await aiInterviewStore.requestProjectFollowUpQuestionToDjango(payload);
    nextQuestion = projectFollowUp?.questions?.[0];
    nextQuestionId = projectFollowUp?.questionIds?.[0];
  } else if (currentQuestionId.value === 5) {
    const techFollowUp =
      await aiInterviewStore.requestTechFollowUpQuestionToDjango(payload);
    nextQuestion = techFollowUp?.questions?.[0];
    nextQuestionId = techFollowUp?.questionIds?.[0];
  } else {
    finished.value = true;
    await nextTick();
    isGenerating.value = true;
    await nextTick();
    alert("ëª¨ë“  ë©´ì ‘ ì§ˆë¬¸ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.");
    clearInterval(timer.value);
    stopRecordingAuto();
    await aiInterviewStore.requestEndInterviewToDjango(payload);
    await aiInterviewStore.requestGetScoreResultListToDjango(payload);
    router.push("/ai-interview/result");
    return;
  }

  if (!nextQuestion || !nextQuestionId) {
    alert("ë‹¤ìŒ ì§ˆë¬¸ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.");
    isGenerating.value = false;
    return;
  }

  currentQuestionId.value = nextQuestionId;
  currentAIMessage.value = nextQuestion;
  sttLog.value = "";
  speakCurrentMessage();

  isGenerating.value = false;
};

onBeforeUnmount(() => {
  if (synth?.speaking) synth.cancel();
  localStorage.removeItem("interviewInfo");
  clearInterval(timer.value);
  window.removeEventListener("beforeunload", handleBeforeUnload);
});

onBeforeRouteLeave((to, from, next) => {
  if (start.value && !finished.value) {
    const answer = window.confirm(
      "ë©´ì ‘ì´ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ë‚˜ê°€ì‹œê² ìŠµë‹ˆê¹Œ?"
    );
    answer ? next() : next(false);
  } else {
    next();
  }
});
const playRecording = () => {
  if (recordedBlob.value) {
    const videoURL = URL.createObjectURL(recordedBlob.value);
    if (previewVideo.value) {
      previewVideo.value.srcObject = null;
      previewVideo.value.src = videoURL;
      previewVideo.value.controls = true;
      previewVideo.value.play();
    }
  }
};
</script>
